{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "categories=['talk.politics.mideast', 'rec.sport.hockey','comp.graphics', 'sci.med', 'sci.space', 'comp.sys.ibm.pc.hardware', 'alt.atheism']\n",
    "df=fetch_20newsgroups(subset='train',shuffle=True,random_state=42)\n",
    "print(len(df.target_names))\n",
    "print(df.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n"
     ]
    }
   ],
   "source": [
    "print(len(df.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv=CountVectorizer()\n",
    "xtrain_count=cv.fit_transform(df.data)\n",
    "print(xtrain_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf=TfidfTransformer()\n",
    "xtrain_tf=tfidf.fit_transform(xtrain_count)\n",
    "print(xtrain_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf=MultinomialNB().fit(xtrain_tf,df.target)\n",
    "df_test=fetch_20newsgroups(subset='test',shuffle=True,random_state=42)\n",
    "\n",
    "# print(df_test.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7738980350504514\n",
      "0.8169144981412639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
    "text_clf1 = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
    "text_clf.fit(df.data,df.target)\n",
    "text_clf1.fit(df.data,df.target)\n",
    "pred=text_clf.predict(df_test.data)\n",
    "pred1=text_clf1.predict(df_test.data)\n",
    "\n",
    "print(np.mean(pred==df_test.target))\n",
    "print(np.mean(pred1==df_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multilayer perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7351301115241635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('clf', MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(15,),random_state=1)),])\n",
    "\n",
    "text_clf.fit(df.data,df.target)\n",
    "pred=text_clf.predict(df_test.data)\n",
    "\n",
    "print(np.mean(pred==df_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8297928836962294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('clf', LogisticRegression()),])\n",
    "\n",
    "text_clf.fit(df.data,df.target)\n",
    "pred=text_clf.predict(df_test.data)\n",
    "\n",
    "print(np.mean(pred==df_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8531598513011153\n",
      "0.851035581518853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', LinearSVC()),])\n",
    "text_clf1 = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('clf', LinearSVC()),])\n",
    "\n",
    "text_clf.fit(df.data,df.target)\n",
    "text_clf1.fit(df.data,df.target)\n",
    "pred=text_clf.predict(df_test.data)\n",
    "pred1=text_clf1.predict(df_test.data)\n",
    "\n",
    "print(np.mean(pred==df_test.target))\n",
    "print(np.mean(pred1==df_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example to test classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "te=[]\n",
    "te.append(\"\"\"From: stark@dwovax.enet.dec.com (Todd I. Stark)\n",
    "Subject: Re: Krillean Photography\n",
    "Organization: Digital Equipment Corporation\n",
    "Lines: 52\n",
    "Distribution: world\n",
    "NNTP-Posting-Host: DWOVAX\n",
    "\n",
    "\n",
    "In article <1rjr1uINNh8@gap.caltech.edu>, carl@SOL1.GPS.CALTECH.EDU (Carl J Lydick) writes...\n",
    ">In article <1993Apr26.204319.11231@ultb.isc.rit.edu>, eas3714@ultb.isc.rit.edu (E.A. Story) writes:\n",
    ">=In article <1rgrsvINNmpr@gap.caltech.edu> carl@SOL1.GPS.CALTECH.EDU writes:\n",
    ">=>Greg:Flame definitely intended here.  Bill was making fun of the misspelling. \n",
    ">=>Go look up the word \"krill.\"  Also, the correct spelling is Kirlian.  It\n",
    ">=>involves taking photographs of corona discharges created by attaching the\n",
    ">=>subject to a high-voltage source, not of some \"aura.\"  It works equally well\n",
    ">=>with inanimate objects.\n",
    ">=\n",
    ">=True.. but what about showing the missing part of a leaf?  Is this\n",
    ">=\"corona discharge\"?\n",
    "> \n",
    ">Yup.  The demonstration to which you refer consists of placing a leaf between\n",
    ">the plates, and taking a Kirlian photograph of it.  You then cut off part of\n",
    ">the leaf, put the top plate back on, and take another Kirlian photograph.  You\n",
    ">see pretty much the same image in both cases.  Turns out the effect isn't\n",
    ">nearly so striking if you take the trouble to clean the plates between\n",
    ">photographs.  Seems that the moisture from the leaf that you left on the place\n",
    ">conducts electricity.  Surprise, surprise!\n",
    "\n",
    "\tThis is true, but it's not quite the whole story.  There were \n",
    "\tactually some people who were more careful in their methodology\n",
    "\twho also replicated the 'phantom leaf effect.'\n",
    "\n",
    "    One of the most influential critics of Kirlian Electrophotography\n",
    "    is a Theosophist (and threfore presumably willing to entertain the\n",
    "    hypothesis of scientific evidence for a human aura, electromagnetic\n",
    "    or otherwise), professor of electrical engineering at London's\n",
    "    City University, and a past president of the Society for Psychic Research \n",
    "    named A. J. Ellison.\n",
    "\n",
    "    After years of studying the method and the claims, Ellison\n",
    "    came to the conclusion that the photographic images are what we\n",
    "    calls 'Lichtenberg Figures,' an effect of intermittent ionization of\n",
    "    the air around the object.  It's a bit more complicated than\n",
    "    'not wiping off the plates,' but it comes down to the same thing\n",
    "    in the end, Kirlian electrophotography has much more limited\n",
    "    value (if any) than was previously widely thought.  Electrical and\n",
    "    magnetic fields generated by the body are much too small to be\n",
    "    of much use diagnostically without very elaborate equipment and\n",
    "    usually also tracer chemicals.\n",
    "\n",
    "\t\t\t\t\tkind regards,\n",
    "\n",
    "\t\t\t\t\ttodd\n",
    "+-----------------------------------------------------------------------------+\n",
    "| Todd I. Stark\t\t\t\t  stark@dwovax.enet.dec.com           |\n",
    "| Digital Equipment Corporation\t\t             (215) 542-3573           |\n",
    "| Philadelphia, Pa. USA                                                       |\n",
    "|    \"(A word is) the skin of a living thought\"  Oliver Wendell Holmes, Jr.   |\n",
    "+-----------------------------------------------------------------------------+\n",
    "\"\"\")\n",
    "for x in text_clf.predict(te):\n",
    "    print(df.target_names[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
